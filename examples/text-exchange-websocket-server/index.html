<!DOCTYPE html>
<html lang="en">

  <head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <script src="https://cdn.jsdelivr.net/npm/protobufjs@7.X.X/dist/protobuf.min.js"></script>
    <title>Pipecat Text Exchange Example</title>
  </head>

  <body>
    <h1>Pipecat Text Exchange Example</h1>
    <h3>You can respond by typing in the text box below or by speaking. Click the microphone to mute your input.</h3>
    <div style="margin: 20px auto; width: 80%; max-width: 800px; text-align: center;">
      <button id="toggleConversationBtn" class="control-btn start">Start</button>
      <button id="toggleMicBtn" class="control-btn mic" disabled>
        <i class="fas fa-microphone"></i>
      </button>
    </div>
    <div id="chatContainer" style="margin: 20px auto; width: 80%; max-width: 800px; height: 400px; border: 1px solid #ccc; overflow-y: auto; padding: 20px;">
    </div>
    <div style="margin: 20px auto; width: 80%; max-width: 800px;">
      <input type="text" id="textInput" placeholder="Type your message..." style="width: calc(100% - 70px); padding: 5px;">
      <button id="sendTextBtn">Send</button>
    </div>
    <style>
      .message {
        display: flex;
        margin-bottom: 10px;
      }
      .message.user {
        justify-content: flex-end;
      }
      .bubble {
        max-width: 70%;
        padding: 10px 15px;
        border-radius: 15px;
        position: relative;
      }
      .sender {
        font-size: 0.8em;
        margin-bottom: 4px;
        color: #666;
      }
      .agent .bubble {
        background-color: #e9ecef;
        margin-right: auto;
        border-bottom-left-radius: 5px;
      }
      .user .bubble {
        background-color: #007bff;
        color: white;
        margin-left: auto;
        border-bottom-right-radius: 5px;
      }
      .control-btn {
        padding: 10px 20px;
        border: none;
        border-radius: 5px;
        margin: 0 5px;
        cursor: pointer;
        font-size: 16px;
        transition: all 0.3s ease;
      }

      .control-btn.start {
        background-color: #28a745;
        color: white;
      }

      .control-btn.end {
        background-color: #dc3545;
        color: white;
      }

      .control-btn.mic {
        background-color: #6c757d;
        color: white;
        width: 44px;
        height: 44px;
        padding: 10px;
        border-radius: 50%;
      }

      .control-btn.mic.active {
        background-color: #28a745;
      }

      .control-btn:disabled {
        opacity: 0.6;
        cursor: not-allowed;
      }
    </style>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.4/css/all.min.css">
    <script>
      const SAMPLE_RATE = 16000;
      const NUM_CHANNELS = 1;
      const PLAY_TIME_RESET_THRESHOLD_MS = 1.0;

      // The protobuf type. We will load it later.
      let Frame = null;

      // The websocket connection.
      let ws = null;

      // The audio context
      let audioContext = null;

      // The audio context media stream source
      let source = null;

      // The microphone stream from getUserMedia. SHould be sampled to the
      // proper sample rate.
      let microphoneStream = null;

      // Script processor to get data from microphone.
      let scriptProcessor = null;

      // AudioContext play time.
      let playTime = 0;

      // Last time we received a websocket message.
      let lastMessageTime = 0;

      // Whether we should be playing audio.
      let isPlaying = false;

      let isConversationActive = false;
      let isMicActive = true;

      const toggleConversationBtn = document.getElementById('toggleConversationBtn');
      const toggleMicBtn = document.getElementById('toggleMicBtn');

      function updateConversationButtonState() {
        if (isConversationActive) {
          toggleConversationBtn.textContent = 'End';
          toggleConversationBtn.classList.remove('start');
          toggleConversationBtn.classList.add('end');
          toggleMicBtn.disabled = false;
        } else {
          toggleConversationBtn.textContent = 'Start';
          toggleConversationBtn.classList.remove('end');
          toggleConversationBtn.classList.add('start');
          toggleMicBtn.disabled = true;
        }
      }

      function updateMicButtonState() {
        if (isMicActive) {
          toggleMicBtn.classList.add('active');
          toggleMicBtn.querySelector('i').classList.remove('fa-microphone-slash');
          toggleMicBtn.querySelector('i').classList.add('fa-microphone');
        } else {
          toggleMicBtn.classList.remove('active');
          toggleMicBtn.querySelector('i').classList.remove('fa-microphone');
          toggleMicBtn.querySelector('i').classList.add('fa-microphone-slash');
        }
      }

      function toggleConversation() {
        isConversationActive = !isConversationActive;
        updateConversationButtonState();

        if (isConversationActive) {
          startAudioBtnHandler();
        } else {
          stopAudioBtnHandler();
        }
      }

      function toggleMic() {
        isMicActive = !isMicActive;
        updateMicButtonState();

        if (scriptProcessor) {
          if (isMicActive) {
            source.connect(scriptProcessor);
          } else {
            source.disconnect(scriptProcessor);
          }
        }
      }

      function initWebSocket() {
          ws = new WebSocket('ws://localhost:8765');
          // This is so `event.data` is already an ArrayBuffer.
          ws.binaryType = 'arraybuffer';

          ws.addEventListener('open', handleWebSocketOpen);
          ws.addEventListener('message', handleWebSocketMessage);
          ws.addEventListener('close', (event) => {
              console.log('WebSocket connection closed.', event.code, event.reason);
              stopAudio(false);
          });
          ws.addEventListener('error', (event) => console.error('WebSocket error:', event));
      }

      function handleWebSocketOpen(event) {
        console.log('WebSocket connection established.', event)

        navigator.mediaDevices.getUserMedia({
              audio: {
                  sampleRate: SAMPLE_RATE,
                  channelCount: NUM_CHANNELS,
                  autoGainControl: true,
                  echoCancellation: true,
                  noiseSuppression: true,
              }
          }).then((stream) => {
              microphoneStream = stream;
              // 512 is closest thing to 200ms.
              scriptProcessor = audioContext.createScriptProcessor(512, 1, 1);
              source = audioContext.createMediaStreamSource(stream);
              source.connect(scriptProcessor);
              scriptProcessor.connect(audioContext.destination);

              scriptProcessor.onaudioprocess = (event) => {
                  if (!ws) {
                      return;
                  }

                  const audioData = event.inputBuffer.getChannelData(0);
                  const pcmS16Array = convertFloat32ToS16PCM(audioData);
                  const pcmByteArray = new Uint8Array(pcmS16Array.buffer);
                  const frame = Frame.create({
                      audio: {
                          audio: Array.from(pcmByteArray),
                          sampleRate: SAMPLE_RATE,
                          numChannels: NUM_CHANNELS
                      }
                  });
                  const encodedFrame = new Uint8Array(Frame.encode(frame).finish());
                  ws.send(encodedFrame);
              };
          }).catch((error) => console.error('Error accessing microphone:', error));
      }

      let chatContainer = document.getElementById('chatContainer');

      function addMessageToChat(text, isUser) {
        const messageDiv = document.createElement('div');
        messageDiv.className = `message ${isUser ? 'user' : 'agent'}`;

        const bubble = document.createElement('div');
        bubble.className = 'bubble';

        const sender = document.createElement('div');
        sender.className = 'sender';
        sender.textContent = isUser ? 'User' : 'Agent';

        const content = document.createElement('div');
        content.className = 'content';
        content.textContent = text;

        bubble.appendChild(sender);
        bubble.appendChild(content);
        messageDiv.appendChild(bubble);
        chatContainer.appendChild(messageDiv);

        // Auto scroll to bottom
        chatContainer.scrollTop = chatContainer.scrollHeight;
      }

      function handleWebSocketMessage(event) {
          const arrayBuffer = event.data;
          try {
              const parsedFrame = Frame.decode(new Uint8Array(arrayBuffer));

              if (parsedFrame.text) {
                  console.log('Received text frame:', {
                      id: parsedFrame.text.id,
                      name: parsedFrame.text.name,
                      text: parsedFrame.text.text
                  });
                  addMessageToChat(parsedFrame.text.text, false);
              }
              else if (parsedFrame.audio && isPlaying) {
                  enqueueAudioFromProto(arrayBuffer);
              }
          } catch (e) {
              console.error('Error decoding message:', e);
          }
      }

      function enqueueAudioFromProto(arrayBuffer) {
          const parsedFrame = Frame.decode(new Uint8Array(arrayBuffer));
          if (!parsedFrame?.audio) {
              return false;
          }

          // Reset play time if it's been a while we haven't played anything.
          const diffTime = audioContext.currentTime - lastMessageTime;
          if ((playTime == 0) || (diffTime > PLAY_TIME_RESET_THRESHOLD_MS)) {
              playTime = audioContext.currentTime;
          }
          lastMessageTime = audioContext.currentTime;

          // We should be able to use parsedFrame.audio.audio.buffer but for
          // some reason that contains all the bytes from the protobuf message.
          const audioVector = Array.from(parsedFrame.audio.audio);
          const audioArray = new Uint8Array(audioVector);

          audioContext.decodeAudioData(audioArray.buffer, function(buffer) {
              const source = new AudioBufferSourceNode(audioContext);
              source.buffer = buffer;
              source.start(playTime);
              source.connect(audioContext.destination);
              playTime = playTime + buffer.duration;
          });
      }

      function convertFloat32ToS16PCM(float32Array) {
          let int16Array = new Int16Array(float32Array.length);

          for (let i = 0; i < float32Array.length; i++) {
              let clampedValue = Math.max(-1, Math.min(1, float32Array[i]));
              int16Array[i] = clampedValue < 0 ? clampedValue * 32768 : clampedValue * 32767;
          }
          return int16Array;
      }

      function startAudioBtnHandler() {
          if (!navigator.mediaDevices || !navigator.mediaDevices.getUserMedia) {
              alert('getUserMedia is not supported in your browser.');
              return;
          }

          audioContext = new (window.AudioContext || window.webkitAudioContext)({
              latencyHint: 'interactive',
              sampleRate: SAMPLE_RATE
          });

          isPlaying = true;

          initWebSocket();
      }

      function stopAudioBtnHandler() {
          stopAudio(true);
      }

      function stopAudio(closeWebsocket) {
          playTime = 0;
          isPlaying = false;

          if (ws && closeWebsocket) {
              ws.close();
              ws = null;
          }

          if (scriptProcessor) {
              scriptProcessor.disconnect();
          }
          if (source) {
              source.disconnect();
          }
      }

      function sendTextMessage(text) {
          if (!ws || ws.readyState !== WebSocket.OPEN) {
              console.error('WebSocket is not connected');
              return;
          }

          const frame = Frame.create({
              transcription: {
                  text: text,
                  timestamp: String(Date.now() / 1000),
                  userId: 'user'
              }
          });
          const encodedFrame = new Uint8Array(Frame.encode(frame).finish());
          ws.send(encodedFrame);
      }

      // Text input handling
      const textInput = document.getElementById('textInput');
      const sendTextBtn = document.getElementById('sendTextBtn');

      function handleTextSubmit() {
          const text = textInput.value.trim();
          if (text) {
              sendTextMessage(text);
              addMessageToChat(text, true);
              textInput.value = '';
          }
      }

      textInput.addEventListener('keypress', (e) => {
          if (e.key === 'Enter') {
              handleTextSubmit();
          }
      });

      sendTextBtn.addEventListener('click', handleTextSubmit);

      toggleConversationBtn.addEventListener('click', toggleConversation);
      toggleMicBtn.addEventListener('click', toggleMic);

      updateConversationButtonState();
      updateMicButtonState();

      const proto = protobuf.load('frames.proto', (err, root) => {
          if (err) {
              throw err;
          }
          Frame = root.lookupType('pipecat.Frame');
          toggleConversationBtn.disabled = false;
      });
    </script>
  </body>

</html>
